{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8cc4eb-8acb-427a-8691-e384dfa6b55c",
   "metadata": {},
   "source": [
    "# Task 1 (Fixed, half of Task 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d99f0",
   "metadata": {},
   "source": [
    "# Data exploration of features obtained via transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f5cc3",
   "metadata": {},
   "source": [
    "The objective of this notebook is to:\n",
    "- identify the type of data we are ingesting\n",
    "- test the model with different hyperparameters and calculate each test root mean square error per cristaline system\n",
    "- present the best 3 models and their performance by category(cristaline system)\n",
    "\n",
    "In order to achieve this objectives we are going to use the notebooks made/provided by Dr.Juan Ivan Gomez and his analysis of features using transfer learnging techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verificar si se está utilizando la GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU encontrada.')\n",
    "else:\n",
    "    print(\"No se encontró GPU. Se utilizará la CPU.\")\n",
    "\n",
    "# Librerias adicionales:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e107ee",
   "metadata": {},
   "source": [
    "We retrieve the features obtained in the previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f37879",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = \"C:/Users/marit/Documents/UPY Estancia I/latpar_project/LatPars_SuperModel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55fb1be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231632, 480)\n",
      "(231632, 480)\n",
      "(231632, 480)\n",
      "(231632, 480)\n"
     ]
    }
   ],
   "source": [
    "raw_features = {}\n",
    "\n",
    "for size in ['0050','0100','0250','macro']:\n",
    "    raw_features[f'hf_{size}'] = np.load(directorio + f'hf_{size}.npy')\n",
    "    y = np.load(\"C:/Users/marit/Documents/UPY Estancia I/latpar_project/latpars.npy\")    # Not needed.\n",
    "    print(raw_features[f'hf_{size}'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a05b98-0eee-4dc8-b7de-d0b36b4e4388",
   "metadata": {},
   "source": [
    "Exploring a little bit of the first array to have a better vision of what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ce4691-f705-4dda-86eb-aa3452d0b73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>470</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.584560</td>\n",
       "      <td>-2.632532</td>\n",
       "      <td>-1.014055</td>\n",
       "      <td>9.017440</td>\n",
       "      <td>-1.718816</td>\n",
       "      <td>6.906417</td>\n",
       "      <td>-2.970533</td>\n",
       "      <td>-1.071763</td>\n",
       "      <td>-2.386293</td>\n",
       "      <td>-0.703034</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.185041</td>\n",
       "      <td>-2.106664</td>\n",
       "      <td>7.848785</td>\n",
       "      <td>-2.494743</td>\n",
       "      <td>-3.143651</td>\n",
       "      <td>6.798447</td>\n",
       "      <td>-3.644854</td>\n",
       "      <td>0.226932</td>\n",
       "      <td>-2.160397</td>\n",
       "      <td>-1.425291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.412087</td>\n",
       "      <td>-3.524274</td>\n",
       "      <td>-0.154388</td>\n",
       "      <td>-0.038311</td>\n",
       "      <td>-1.923892</td>\n",
       "      <td>-1.226420</td>\n",
       "      <td>0.839404</td>\n",
       "      <td>-1.315200</td>\n",
       "      <td>5.070639</td>\n",
       "      <td>-2.445714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322201</td>\n",
       "      <td>0.242484</td>\n",
       "      <td>0.458990</td>\n",
       "      <td>-2.178892</td>\n",
       "      <td>-2.870002</td>\n",
       "      <td>6.599074</td>\n",
       "      <td>-2.306636</td>\n",
       "      <td>0.192461</td>\n",
       "      <td>-1.828919</td>\n",
       "      <td>-3.663251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.422111</td>\n",
       "      <td>-2.329903</td>\n",
       "      <td>-1.268017</td>\n",
       "      <td>-1.909266</td>\n",
       "      <td>-1.972611</td>\n",
       "      <td>-1.261817</td>\n",
       "      <td>2.268379</td>\n",
       "      <td>-1.373033</td>\n",
       "      <td>0.667226</td>\n",
       "      <td>-2.418815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.627661</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.861677</td>\n",
       "      <td>-2.268018</td>\n",
       "      <td>-2.904607</td>\n",
       "      <td>6.590966</td>\n",
       "      <td>-2.628865</td>\n",
       "      <td>0.383755</td>\n",
       "      <td>-1.922455</td>\n",
       "      <td>-4.029851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.445722</td>\n",
       "      <td>-2.811319</td>\n",
       "      <td>0.904307</td>\n",
       "      <td>0.676237</td>\n",
       "      <td>-1.029232</td>\n",
       "      <td>-0.370148</td>\n",
       "      <td>-2.617837</td>\n",
       "      <td>-1.300127</td>\n",
       "      <td>5.016732</td>\n",
       "      <td>2.322985</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.458181</td>\n",
       "      <td>-1.675237</td>\n",
       "      <td>1.538714</td>\n",
       "      <td>-2.200254</td>\n",
       "      <td>-2.892629</td>\n",
       "      <td>7.054496</td>\n",
       "      <td>-3.398879</td>\n",
       "      <td>0.550226</td>\n",
       "      <td>-1.851339</td>\n",
       "      <td>-3.225384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.147546</td>\n",
       "      <td>-3.646213</td>\n",
       "      <td>-0.466969</td>\n",
       "      <td>-2.897175</td>\n",
       "      <td>-2.012797</td>\n",
       "      <td>-1.412958</td>\n",
       "      <td>7.176705</td>\n",
       "      <td>-1.619964</td>\n",
       "      <td>1.425452</td>\n",
       "      <td>-1.206494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081721</td>\n",
       "      <td>0.198071</td>\n",
       "      <td>1.172589</td>\n",
       "      <td>-2.381650</td>\n",
       "      <td>-2.207114</td>\n",
       "      <td>6.628587</td>\n",
       "      <td>-2.073622</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>-2.041709</td>\n",
       "      <td>-4.154495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -2.584560 -2.632532 -1.014055  9.017440 -1.718816  6.906417 -2.970533   \n",
       "1 -1.412087 -3.524274 -0.154388 -0.038311 -1.923892 -1.226420  0.839404   \n",
       "2 -2.422111 -2.329903 -1.268017 -1.909266 -1.972611 -1.261817  2.268379   \n",
       "3  0.445722 -2.811319  0.904307  0.676237 -1.029232 -0.370148 -2.617837   \n",
       "4 -1.147546 -3.646213 -0.466969 -2.897175 -2.012797 -1.412958  7.176705   \n",
       "\n",
       "        7         8         9    ...       470       471       472       473  \\\n",
       "0 -1.071763 -2.386293 -0.703034  ... -1.185041 -2.106664  7.848785 -2.494743   \n",
       "1 -1.315200  5.070639 -2.445714  ...  0.322201  0.242484  0.458990 -2.178892   \n",
       "2 -1.373033  0.667226 -2.418815  ... -0.627661  0.045241  0.861677 -2.268018   \n",
       "3 -1.300127  5.016732  2.322985  ... -1.458181 -1.675237  1.538714 -2.200254   \n",
       "4 -1.619964  1.425452 -1.206494  ... -0.081721  0.198071  1.172589 -2.381650   \n",
       "\n",
       "        474       475       476       477       478       479  \n",
       "0 -3.143651  6.798447 -3.644854  0.226932 -2.160397 -1.425291  \n",
       "1 -2.870002  6.599074 -2.306636  0.192461 -1.828919 -3.663251  \n",
       "2 -2.904607  6.590966 -2.628865  0.383755 -1.922455 -4.029851  \n",
       "3 -2.892629  7.054496 -3.398879  0.550226 -1.851339 -3.225384  \n",
       "4 -2.207114  6.628587 -2.073622  0.563037 -2.041709 -4.154495  \n",
       "\n",
       "[5 rows x 480 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw_features['hf_0100'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb02abd",
   "metadata": {},
   "source": [
    "Now we take a look into the distributions of our data using histograms for the first array 'hf_0100' from the 'raw_features' dictionary. Also we're going to take all this histograms and standard deviations data and save it into a PDF. And lastly it will take all the computed statistics values and save them into a CSV file to have better management of these values to future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2e9abad-d2a8-45b9-9228-79d602431d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file with histograms and standard deviations saved successfully.\n",
      "CSV file with statistics saved successfully.\n"
     ]
    }
   ],
   "source": [
    "data = raw_features['hf_0100']    # Array used in this cell.\n",
    "all_mean = {}\n",
    "all_median = {}\n",
    "all_std_dev = {}    # Empty dictionaries to put all statistics values.\n",
    "\n",
    "\n",
    "with PdfPages('histograms_hf_0100.pdf') as pdf:\n",
    "    for i, values in enumerate(data.T):\n",
    "        \n",
    "        # Compute basic statistics.\n",
    "        mean = np.mean(values)\n",
    "        median = np.median(values)\n",
    "        std_dev = np.std(values)\n",
    "        all_mean[i] = mean\n",
    "        all_median[i] = median \n",
    "        all_std_dev[i] = std_dev    # Saving the values per iteration in its respective dictionary.\n",
    "\n",
    "        # Plotting histogram of the array.\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.hist(values, bins=100, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        plt.title('Histogram of Data Distribution')\n",
    "        plt.xlabel('Values')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Add standard deviation to the plot.\n",
    "        plt.text(0.5, 0.95, f'Standard Deviation: {std_dev:.2f}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Save the current figure to the PDF.\n",
    "        pdf.savefig()\n",
    "        \n",
    "        # Close the current figure to release memory.\n",
    "        plt.close()\n",
    "\n",
    "print(\"PDF file with histograms and standard deviations saved successfully.\")\n",
    "\n",
    "# Name of the output csv file.\n",
    "csv_filename = 'statistics_hf_0100.csv'\n",
    "\n",
    "# Open CSV file in write mode.\n",
    "with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['Index', 'Mean', 'Median', 'Standard Deviation']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row.\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write statistics data to CSV file.\n",
    "    for i in range(len(data.T)):\n",
    "        writer.writerow({'Index': i, 'Mean': all_mean[i], 'Median': all_median[i], 'Standard Deviation': all_std_dev[i]})\n",
    "\n",
    "print(\"CSV file with statistics saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c4107-9ea5-4582-8c5d-8952cc6e8db3",
   "metadata": {},
   "source": [
    "Now we take a look into the distributions of our data using histograms for the first array 'hf_0050' from the 'raw_features' dictionary. Also we're going to take all this histograms and standard deviations data and save it into a PDF. And lastly it will take all the computed statistics values and save them into a CSV file to have better management of these values to future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c89377-37be-4866-9ac8-fa2e5164e6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file with histograms and standard deviations saved successfully.\n",
      "CSV file with statistics saved successfully.\n"
     ]
    }
   ],
   "source": [
    "data = raw_features['hf_0050']    # Array used in this cell.\n",
    "all_mean = {}\n",
    "all_median = {}\n",
    "all_std_dev = {}    # Empty dictionaries to put all statistics values.\n",
    "\n",
    "\n",
    "with PdfPages('histograms_hf_0050.pdf') as pdf:\n",
    "    for i, values in enumerate(data.T):\n",
    "        \n",
    "        # Compute basic statistics.\n",
    "        mean = np.mean(values)\n",
    "        median = np.median(values)\n",
    "        std_dev = np.std(values)\n",
    "        all_mean[i] = mean\n",
    "        all_median[i] = median \n",
    "        all_std_dev[i] = std_dev    # Saving the values per iteration in its respective dictionary.\n",
    "\n",
    "        # Plotting histogram of the array.\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.hist(values, bins=100, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        plt.title('Histogram of Data Distribution')\n",
    "        plt.xlabel('Values')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Add standard deviation to the plot.\n",
    "        plt.text(0.5, 0.95, f'Standard Deviation: {std_dev:.2f}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Save the current figure to the PDF.\n",
    "        pdf.savefig()\n",
    "        \n",
    "        # Close the current figure to release memory.\n",
    "        plt.close()\n",
    "\n",
    "print(\"PDF file with histograms and standard deviations saved successfully.\")\n",
    "\n",
    "# Name of the output csv file.\n",
    "csv_filename = 'statistics_hf_0050.csv'\n",
    "\n",
    "# Open CSV file in write mode.\n",
    "with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['Index', 'Mean', 'Median', 'Standard Deviation']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row.\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write statistics data to CSV file.\n",
    "    for i in range(len(data.T)):\n",
    "        writer.writerow({'Index': i, 'Mean': all_mean[i], 'Median': all_median[i], 'Standard Deviation': all_std_dev[i]})\n",
    "\n",
    "print(\"CSV file with statistics saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d32c1a-27a5-4c33-969b-f921569daf8d",
   "metadata": {},
   "source": [
    "Now we take a look into the distributions of our data using histograms for the first array 'hf_0250' from the 'raw_features' dictionary. Also we're going to take all this histograms and standard deviations data and save it into a PDF. And lastly it will take all the computed statistics values and save them into a CSV file to have better management of these values to future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b4c4a8b-8ee2-4c5f-831d-35a8bab8dd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file with histograms and standard deviations saved successfully.\n",
      "CSV file with statistics saved successfully.\n"
     ]
    }
   ],
   "source": [
    "data = raw_features['hf_0250']    # Array used in this cell.\n",
    "all_mean = {}\n",
    "all_median = {}\n",
    "all_std_dev = {}    # Empty dictionaries to put all statistics values.\n",
    "\n",
    "\n",
    "with PdfPages('histograms_hf_0250.pdf') as pdf:\n",
    "    for i, values in enumerate(data.T):\n",
    "        \n",
    "        # Compute basic statistics.\n",
    "        mean = np.mean(values)\n",
    "        median = np.median(values)\n",
    "        std_dev = np.std(values)\n",
    "        all_mean[i] = mean\n",
    "        all_median[i] = median \n",
    "        all_std_dev[i] = std_dev    # Saving the values per iteration in its respective dictionary.\n",
    "\n",
    "        # Plotting histogram of the array.\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.hist(values, bins=100, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        plt.title('Histogram of Data Distribution')\n",
    "        plt.xlabel('Values')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Add standard deviation to the plot.\n",
    "        plt.text(0.5, 0.95, f'Standard Deviation: {std_dev:.2f}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Save the current figure to the PDF.\n",
    "        pdf.savefig()\n",
    "        \n",
    "        # Close the current figure to release memory.\n",
    "        plt.close()\n",
    "\n",
    "print(\"PDF file with histograms and standard deviations saved successfully.\")\n",
    "\n",
    "# Name of the output csv file.\n",
    "csv_filename = 'statistics_hf_0250.csv'\n",
    "\n",
    "# Open CSV file in write mode.\n",
    "with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['Index', 'Mean', 'Median', 'Standard Deviation']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row.\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write statistics data to CSV file.\n",
    "    for i in range(len(data.T)):\n",
    "        writer.writerow({'Index': i, 'Mean': all_mean[i], 'Median': all_median[i], 'Standard Deviation': all_std_dev[i]})\n",
    "\n",
    "print(\"CSV file with statistics saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205374b-abd5-444b-8d55-1e20ffcf178d",
   "metadata": {},
   "source": [
    "Now we take a look into the distributions of our data using histograms for the first array 'hf_macro' from the 'raw_features' dictionary. Also we're going to take all this histograms and standard deviations data and save it into a PDF. And lastly it will take all the computed statistics values and save them into a CSV file to have better management of these values to future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "232d20f7-f49c-4bb1-99e5-e5900cf99372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file with histograms and standard deviations saved successfully.\n",
      "CSV file with statistics saved successfully.\n"
     ]
    }
   ],
   "source": [
    "data = raw_features['hf_macro']    # Array used in this cell.\n",
    "all_mean = {}\n",
    "all_median = {}\n",
    "all_std_dev = {}    # Empty dictionaries to put all statistics values.\n",
    "\n",
    "\n",
    "with PdfPages('histograms_hf_macro.pdf') as pdf:\n",
    "    for i, values in enumerate(data.T):\n",
    "        \n",
    "        # Compute basic statistics.\n",
    "        mean = np.mean(values)\n",
    "        median = np.median(values)\n",
    "        std_dev = np.std(values)\n",
    "        all_mean[i] = mean\n",
    "        all_median[i] = median \n",
    "        all_std_dev[i] = std_dev    # Saving the values per iteration in its respective dictionary.\n",
    "\n",
    "        # Plotting histogram of the array.\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.hist(values, bins=100, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        plt.title('Histogram of Data Distribution')\n",
    "        plt.xlabel('Values')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Add standard deviation to the plot.\n",
    "        plt.text(0.5, 0.95, f'Standard Deviation: {std_dev:.2f}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "\n",
    "        # Save the current figure to the PDF.\n",
    "        pdf.savefig()\n",
    "        \n",
    "        # Close the current figure to release memory.\n",
    "        plt.close()\n",
    "\n",
    "print(\"PDF file with histograms and standard deviations saved successfully.\")\n",
    "\n",
    "# Name of the output csv file.\n",
    "csv_filename = 'statistics_hf_macro.csv'\n",
    "\n",
    "# Open CSV file in write mode.\n",
    "with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['Index', 'Mean', 'Median', 'Standard Deviation']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header row.\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write statistics data to CSV file.\n",
    "    for i in range(len(data.T)):\n",
    "        writer.writerow({'Index': i, 'Mean': all_mean[i], 'Median': all_median[i], 'Standard Deviation': all_std_dev[i]})\n",
    "\n",
    "print(\"CSV file with statistics saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31184a-e39a-4514-9ae7-d315e9f2d611",
   "metadata": {},
   "source": [
    "# Task 2 (Continuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25326855-e2e8-4cb1-9b85-fa5473e0d5e7",
   "metadata": {},
   "source": [
    "After having obtained the average values and standard deviation of each trait, samples that are outside three standard deviations (outliers) will be eliminated.\n",
    "\n",
    "To achive this first, we're going to load the CSVs with the statistical values to look at the outliers of the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d62cb6-790f-4d80-b11c-c42d3be00378",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_hf_0100 = pd.read_csv(\"C:/Users/marit/Documents/UPY Estancia I/statistics_hf_0100.csv\") # Loading CSVs as pandas objects.\n",
    "csv_hf_0050 = pd.read_csv(\"C:/Users/marit/Documents/UPY Estancia I/statistics_hf_0050.csv\")\n",
    "csv_hf_0250 = pd.read_csv(\"C:/Users/marit/Documents/UPY Estancia I/statistics_hf_0250.csv\")\n",
    "csv_hf_macro = pd.read_csv(\"C:/Users/marit/Documents/UPY Estancia I/statistics_hf_macro.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe646a92-0fee-451c-a32c-3cede346bc36",
   "metadata": {},
   "source": [
    "Now that we have loaded the respective CSV files of our statistics values from the first part of this notebook, we will look into the standard deviations and with the rows that are outside three standard deviation we're going to eliminate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c639dc2-8560-4ac8-83f9-0f3d085136ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = {}    # Empty dictionary to save the new and fixed arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93af95a-1ee4-40b6-b5f9-669f6645168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_2 = {}    # Empty dictionary to save the new and fixed arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7388044d-5273-4e31-8b00-93ed88f5b354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.287814</td>\n",
       "      <td>-1.391897</td>\n",
       "      <td>2.925534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.610887</td>\n",
       "      <td>-1.525966</td>\n",
       "      <td>3.001665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.390859</td>\n",
       "      <td>-0.915662</td>\n",
       "      <td>1.811028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.980028</td>\n",
       "      <td>-2.312430</td>\n",
       "      <td>2.743423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.130426</td>\n",
       "      <td>-1.632416</td>\n",
       "      <td>2.144145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index      Mean    Median  Standard Deviation\n",
       "0      0 -0.287814 -1.391897            2.925534\n",
       "1      1 -0.610887 -1.525966            3.001665\n",
       "2      2 -0.390859 -0.915662            1.811028\n",
       "3      3 -0.980028 -2.312430            2.743423\n",
       "4      4 -1.130426 -1.632416            2.144145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_hf_0100.head()    # Taking a look into the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "890f1a9f-a950-4a04-b03f-acdec34f0e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array original: (231632, 480)\n",
      "Array filtrado: (231632, 480)\n"
     ]
    }
   ],
   "source": [
    "# Collecting the mean and the standard deviation from the CSV file.\n",
    "mean = csv_hf_0100.iloc[:,1]\n",
    "std_dev = csv_hf_0100.iloc[:,3]\n",
    "\n",
    "all_limsup = {}    # Empty dicts to save indices and the range of the limits.\n",
    "all_liminf = {}\n",
    "\n",
    "# Getting superior and inferior limits.\n",
    "for i in range(csv_hf_0100.shape[0]):\n",
    "    limsup = mean[i] + (3 * std_dev[i])\n",
    "    liminf = mean[i] - (3 * std_dev[i])\n",
    "    all_limsup[i] = limsup\n",
    "    all_liminf[i] = liminf\n",
    "\n",
    "# Create a new array to store the values within the range.\n",
    "new_features['hf_0100'] = np.zeros_like(raw_features['hf_0100'])\n",
    "\n",
    "# Iterate over the columns of the original array.\n",
    "for i in range(raw_features['hf_0100'].shape[1]):\n",
    "    # Get the upper and lower limits for this column.\n",
    "    limsup = all_limsup[i]\n",
    "    liminf = all_liminf[i]\n",
    "    \n",
    "    # Filter values that are within the range.\n",
    "    column_vals = raw_features['hf_0100'][:, i]\n",
    "    column_vals_filtrados = column_vals[(column_vals >= liminf) & (column_vals <= limsup)]\n",
    "    \n",
    "    # Assign the filtered values to the corresponding column of the new array.\n",
    "    new_features['hf_0100'][:len(column_vals_filtrados), i] = column_vals_filtrados\n",
    "\n",
    "print(\"Raw Array:\", raw_features['hf_0100'].shape)\n",
    "print(\"Filtered Array:\", new_features['hf_0100'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffeeb18d-2c70-4b91-a2e6-d829e3ecc7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Array: (231632, 480)\n",
      "Filtered Array: (231632, 480)\n"
     ]
    }
   ],
   "source": [
    "# Collecting the mean and the standard deviation from the CSV file.\n",
    "mean = csv_hf_0050.iloc[:,1]\n",
    "std_dev = csv_hf_0050.iloc[:,3]\n",
    "\n",
    "all_limsup = {}    # Empty dicts to save indices and the range of the limits.\n",
    "all_liminf = {}\n",
    "\n",
    "# Getting superior and inferior limits.\n",
    "for i in range(csv_hf_0050.shape[0]):\n",
    "    limsup = mean[i] + (3 * std_dev[i])\n",
    "    liminf = mean[i] - (3 * std_dev[i])\n",
    "    all_limsup[i] = limsup\n",
    "    all_liminf[i] = liminf\n",
    "\n",
    "# Create a new array to store the values within the range.\n",
    "new_features['hf_0050'] = np.zeros_like(raw_features['hf_0050'])\n",
    "\n",
    "# Iterate over the columns of the original array.\n",
    "for i in range(raw_features['hf_0050'].shape[1]):\n",
    "    # Get the upper and lower limits for this column.\n",
    "    limsup = all_limsup[i]\n",
    "    liminf = all_liminf[i]\n",
    "    \n",
    "    # Filter values that are within the range.\n",
    "    column_vals = raw_features['hf_0050'][:, i]\n",
    "    column_vals_filtrados = column_vals[(column_vals >= liminf) & (column_vals <= limsup)]\n",
    "    \n",
    "    # Assign the filtered values to the corresponding column of the new array.\n",
    "    new_features['hf_0050'][:len(column_vals_filtrados), i] = column_vals_filtrados\n",
    "\n",
    "print(\"Raw Array:\", raw_features['hf_0050'].shape)\n",
    "print(\"Filtered Array:\", new_features['hf_0050'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0210d964-b47f-4853-9fc8-eb434d39a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Array: (231632, 480)\n",
      "Filtered Array: (231632, 480)\n"
     ]
    }
   ],
   "source": [
    "# Collecting the mean and the standard deviation from the CSV file.\n",
    "mean = csv_hf_0250.iloc[:,1]\n",
    "std_dev = csv_hf_0250.iloc[:,3]\n",
    "\n",
    "all_limsup = {}    # Empty dicts to save indices and the range of the limits.\n",
    "all_liminf = {}\n",
    "\n",
    "# Getting superior and inferior limits.\n",
    "for i in range(csv_hf_0250.shape[0]):\n",
    "    limsup = mean[i] + (3 * std_dev[i])\n",
    "    liminf = mean[i] - (3 * std_dev[i])\n",
    "    all_limsup[i] = limsup\n",
    "    all_liminf[i] = liminf\n",
    "\n",
    "# Create a new array to store the values within the range.\n",
    "new_features['hf_0250'] = np.zeros_like(raw_features['hf_0250'])\n",
    "\n",
    "# Iterate over the columns of the original array.\n",
    "for i in range(raw_features['hf_0250'].shape[1]):\n",
    "    # Get the upper and lower limits for this column.\n",
    "    limsup = all_limsup[i]\n",
    "    liminf = all_liminf[i]\n",
    "    \n",
    "    # Filter values that are within the range.\n",
    "    column_vals = raw_features['hf_0250'][:, i]\n",
    "    column_vals_filtrados = column_vals[(column_vals >= liminf) & (column_vals <= limsup)]\n",
    "    \n",
    "    # Assign the filtered values to the corresponding column of the new array.\n",
    "    new_features['hf_0250'][:len(column_vals_filtrados), i] = column_vals_filtrados\n",
    "\n",
    "print(\"Raw Array:\", raw_features['hf_0250'].shape)\n",
    "print(\"Filtered Array:\", new_features['hf_0250'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2799babd-6d23-4511-bc1e-27d521cf3923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Array: (231632, 480)\n",
      "Filtered Array: (231632, 480)\n"
     ]
    }
   ],
   "source": [
    "# Collecting the mean and the standard deviation from the CSV file.\n",
    "mean = csv_hf_macro.iloc[:,1]\n",
    "std_dev = csv_hf_macro.iloc[:,3]\n",
    "\n",
    "all_limsup = {}    # Empty dicts to save indices and the range of the limits.\n",
    "all_liminf = {}\n",
    "\n",
    "# Getting superior and inferior limits.\n",
    "for i in range(csv_hf_macro.shape[0]):\n",
    "    limsup = mean[i] + (3 * std_dev[i])\n",
    "    liminf = mean[i] - (3 * std_dev[i])\n",
    "    all_limsup[i] = limsup\n",
    "    all_liminf[i] = liminf\n",
    "\n",
    "# Create a new array to store the values within the range.\n",
    "new_features['hf_macro'] = np.zeros_like(raw_features['hf_macro'])\n",
    "\n",
    "# Iterate over the columns of the original array.\n",
    "for i in range(raw_features['hf_macro'].shape[1]):\n",
    "    # Get the upper and lower limits for this column.\n",
    "    limsup = all_limsup[i]\n",
    "    liminf = all_liminf[i]\n",
    "    \n",
    "    # Filter values that are within the range.\n",
    "    column_vals = raw_features['hf_macro'][:, i]\n",
    "    column_vals_filtrados = column_vals[(column_vals >= liminf) & (column_vals <= limsup)]\n",
    "    \n",
    "    # Assign the filtered values to the corresponding column of the new array.\n",
    "    new_features['hf_macro'][:len(column_vals_filtrados), i] = column_vals_filtrados\n",
    "\n",
    "print(\"Raw Array:\", raw_features['hf_macro'].shape)\n",
    "print(\"Filtered Array:\", new_features['hf_macro'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc8ca090-e77c-4d1a-8d5b-636443209e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, saving each fixed array from the new dictionary into a (.npy) file.\n",
    "np.save('hf_0100_fix', new_features['hf_0100'])\n",
    "np.save('hf_0050_fix', new_features['hf_0050'])\n",
    "np.save('hf_0250_fix', new_features['hf_0250'])\n",
    "np.save('hf_macro_fix', new_features['hf_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69336422-5231-40fb-ac38-6c8792f79ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of file 1 before cleaning: (231632, 480)\n",
      "Shape of file 1 after cleaning: (221112, 480)\n",
      "Shape of file 2 before cleaning: (231632, 480)\n",
      "Shape of file 2 after cleaning: (221113, 480)\n",
      "Shape of file 3 before cleaning: (231632, 480)\n",
      "Shape of file 3 after cleaning: (221113, 480)\n",
      "Shape of file 4 before cleaning: (231632, 480)\n",
      "Shape of file 4 after cleaning: (221113, 480)\n"
     ]
    }
   ],
   "source": [
    "# For last, just cleaning the fixed array files taking off the rows that contains the zeros.\n",
    "import numpy as np    # Just to not have to rerun all the notebook.\n",
    "\n",
    "def clean_rows_with_zeros(array):\n",
    "    # Find rows that do not contain zeros.\n",
    "    non_zero_rows = np.all(array != 0, axis=1)\n",
    "    # Filter the array to get only rows that do not contain zeros.\n",
    "    clean_array = array[non_zero_rows]\n",
    "    return clean_array\n",
    "\n",
    "# Load .npy files.\n",
    "file1 = np.load('C:/Users/marit/Documents/UPY Estancia I/hf_0100_fix.npy')\n",
    "file2 = np.load('C:/Users/marit/Documents/UPY Estancia I/hf_0050_fix.npy')\n",
    "file3 = np.load('C:/Users/marit/Documents/UPY Estancia I/hf_0250_fix.npy')\n",
    "file4 = np.load('C:/Users/marit/Documents/UPY Estancia I/hf_macro_fix.npy')\n",
    "\n",
    "# Clean the files.\n",
    "file1_clean = clean_rows_with_zeros(file1)\n",
    "file2_clean = clean_rows_with_zeros(file2)\n",
    "file3_clean = clean_rows_with_zeros(file3)\n",
    "file4_clean = clean_rows_with_zeros(file4)\n",
    "\n",
    "# Check shapes.\n",
    "print(\"Shape of file 1 before cleaning:\", file1.shape)\n",
    "print(\"Shape of file 1 after cleaning:\", file1_clean.shape)\n",
    "print(\"Shape of file 2 before cleaning:\", file2.shape)\n",
    "print(\"Shape of file 2 after cleaning:\", file2_clean.shape)\n",
    "print(\"Shape of file 3 before cleaning:\", file3.shape)\n",
    "print(\"Shape of file 3 after cleaning:\", file3_clean.shape)\n",
    "print(\"Shape of file 4 before cleaning:\", file4.shape)\n",
    "print(\"Shape of file 4 after cleaning:\", file4_clean.shape)\n",
    "\n",
    "# Now, again saving each fixed array from the new dictionary into a (.npy) file.\n",
    "np.save('hf_0100_full_fix', file1_clean)\n",
    "np.save('hf_0050_full_fix', file2_clean)\n",
    "np.save('hf_0250_full_fix', file3_clean)\n",
    "np.save('hf_macro_full_fix', file4_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
